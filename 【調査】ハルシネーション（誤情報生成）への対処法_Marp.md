---
marp: true
title: 生成AIのハルシネーション（誤情報生成）への対処法
description: 生成AIのハルシネーション現象の原因と具体的な対策について解説
paginate: true
theme: gaia
footer: '生成AIのハルシネーション対処法'
header: ''
---

<!--
_class: lead
_paginate: false
-->

# 【社内向け】生成AIのハルシネーション（誤情報生成）への対処法

**安全で効果的なAI活用のために**

---

## 1. はじめに

本プレゼンテーションでは、生成AIが事実に基づかない情報を生成する**「ハルシネーション」**について解説します。

- **ハルシネーション**とは、AIがまるで幻覚を見ているかのように、もっともらしい嘘の情報を生成する現象
- 生成AIを安全かつ有効に活用するために不可欠な知識
- 原因と対策を理解し、適切に対処することが重要

---

<!--
_class: lead
-->

# 2. ハルシネーションの主な原因

---

## 2.1. 学習データの問題
<style scoped>
section {
  font-size: 2.3em;
}
</style>
### データの質と量
- **誤りを含むデータ**: 学習データに誤情報が含まれている
- **古い情報**: 情報が時代遅れになっている
- **データ量不足**: 特定分野の学習データが不十分

### 情報の不足
- 特定トピックの学習データが不足
- AIが既知情報から**推測**で回答を生成
- 結果として誤った情報を生み出す

---

## 2.2. 生成AIモデル自体の問題
<style scoped>
section {
  font-size: 2.4em;
}
### モデルの構造的限界
- **確率的予測**: 次に来る単語を確率で予測
- **文脈理解の不完全性**: 完全な理解ではなく統計的処理
- もっともらしいだけで誤った情報を生成

### 過学習の影響
- 学習データに過剰適応
- 特定パターンに偏った回答
- ハルシネーションの原因となる

---

## 2.3. プロンプト（指示）の問題
<style scoped>
section {
  font-size: 2.4em;
}
</style>

### 曖昧な指示
- **不明確な質問**: 何を求めているかが不明
- **情報不足**: 必要な文脈や条件が欠如
- **想定外の回答**: AIが意図を誤解

### 具体例
❌ **悪い例**: 「〇〇について教えて」  
✅ **良い例**: 「〇〇の概要を、初心者向けに3つのポイントで説明してください」

---

<!--
_class: lead
-->

# 3. ハルシネーションへの対処法

---

## 3.1. 基本的な対策
<style scoped>
section {
  font-size: 2.4em;
}
</style>

### ファクトチェックの徹底
- **最も重要**: AIの出力を鵜呑みにしない
- **人間による検証**: 必ず事実確認を実施
- **複数ソース確認**: 信頼できる情報源との照合

### プロンプトエンジニアリング
- **具体的な指示**: 曖昧さを排除
- **文脈の提供**: 必要な背景情報を含める
- **出力形式の指定**: 求める回答の形式を明示

---

## 3.2. 技術的な対策

### RAG（Retrieval-Augmented Generation）
- **外部データベース検索**: 信頼できる情報源を参照
- **知識の補強**: AIの知識を最新情報で補完
- **回答精度の向上**: より正確な情報生成

### グラウンディング
- **情報源の限定**: 特定の信頼できるデータベースを参照
- **不確実性の排除**: 曖昧な情報源への依存を防止
- **品質管理**: 一定レベル以上の情報のみ使用

---

## 3.3. 運用面での対策

### Human-in-the-Loop
- **人間による監視**: AI出力の継続的な監視
- **修正とフィードバック**: 誤りの修正と学習への反映
- **継続的改善**: AIの精度を段階的に向上

### チーム体制
- **複数人での確認**: 一人だけでなくチームでチェック
- **専門家の関与**: 分野の専門家による検証
- **定期的な見直し**: 対策の有効性を定期評価

---

<!--
_class: lead
-->

# 4. まとめ

---

## 4. まとめ

### 重要なポイント
- **ハルシネーションは避けられないリスク**: 完全な防止は困難
- **適切な対策で大幅にリスク軽減可能**: 正しい知識と手順で安全に活用
- **人間とAIの協働が鍵**: 人間の判断力とAIの処理能力の組み合わせ

### 実践すべきこと
1. **常にファクトチェック**を行う
2. **明確で具体的なプロンプト**を作成する
3. **複数の情報源**で確認する
4. **チームでの検証体制**を構築する

---

<!--
_paginate: false
-->

## 5. 情報元一覧

- 株式会社SIGNATE
- 株式会社野村総合研究所
- Google Cloud
- DSK株式会社
- 株式会社G-gen
- 株式会社Helpme
- ライセンスカウンター
- 株式会社YRI

**詳細なURL情報は配布資料をご確認ください**

---

<!--
_class: lead
_paginate: false
-->

# ご質問・ディスカッション

**安全なAI活用に向けて** 