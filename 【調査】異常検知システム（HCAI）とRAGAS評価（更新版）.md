# 人間中心AI(HCAI)を実現する異常検知システムのアーキテクチャと評価戦略

## 1. はじめに：私たちの目指すもの

本資料は、私たちが開発する「異常検知システム」のアーキテクチャと、その性能を継続的に改善していくための評価戦略について説明するものです。

**このシステムの目的は、単に異常を検知するだけでなく、人間が状況を正確に理解し、最善の意思決定を下すのをAIが支援する「人間中心のAI（HCAI）」を実現することにあります。**

そのために、以下の3つの核心的な考え方に基づき、システムを設計・評価します。

1.  **パート別評価**: システムを機能ごとに分解し、それぞれに最適な「ものさし」で評価する。
2.  **非同期アーキテクチャ**: 「応答速度」と「詳細な評価」を両立させるため、処理（実行系）と評価（評価系）を分離する。
3.  **スコアカード方式**: システムの健全性を多角的に可視化し、問題点を即座に特定できる仕組みを導入する。

---

## 2. 提案アーキテクチャの全体像

システムの全体像は、「**実行系**」「**評価系**」「**改善ループ**」の3つで構成されます。この「関心の分離」により、応答速度を維持しつつ、詳細な評価と継続的な改善を可能にします。

```mermaid
graph TD
    subgraph "【実行系】高速応答ワークフロー (AWS Step Functions)"
        direction LR
        Input[入力データ] --> StepFunctions_Start((Start))
        StepFunctions_Start --> Detect_Parallel[並列検知<br>①異常検知<br>②乖離検知]
        Detect_Parallel --> Analyze[ナレッジ検索 & 分析<br>③RAG]
        Analyze --> External_Info[外部情報取得<br>④Tavily]
        External_Info --> Report_Out[分析レポート出力]
        Report_Out --> User[ユーザー]
        
        %% ログ保存
        Detect_Parallel -- ログ --> S3[(S3<br>評価用データ)]
        Analyze -- ログ --> S3
        External_Info -- ログ --> S3
    end

    subgraph "【評価系】非同期評価ワークフロー"
        S3 -- トリガー --> Eval_Lambda{評価プロセス<br>(Lambda/EventBridge)}
        Eval_Lambda --> Part1_Eval["パート①,②評価<br>(Precision/Recall)"]
        Eval_Lambda --> Part3_Eval["パート③評価<br>(RAGAS)"]
        
        Part1_Eval -- 結果 --> Scorecard[スコアカード<br>ダッシュボード]
        Part3_Eval -- 結果 --> Scorecard
    end

    subgraph "【改善ループ】人間中心のAI (HCAI)"
        User -- フィードバック --> Feedback_DB[(フィードバックDB)]
        Feedback_DB -- データ --> Finetuning[モデル改善<br>ナレッジDB更新]
    end
    
    style S3 fill:#FF9900,stroke:#333,stroke-width:2px
    style User fill:#D3D3D3,stroke:#333,stroke-width:2px
```

### 2.1. 実行系：AWS Step Functionsによる安定した処理
-   **役割**: ユーザーからの要求に対し、「検知→分析→レポート出力」という一連の処理を迅速かつ確実に実行します。
-   **技術**: AWS Step Functionsを採用し、処理の流れを明確に定義することで、予測可能で安定した動作を実現します。

### 2.2. 評価系：分離された非同期評価
-   **役割**: 実行系が完了した後、保存されたログデータを元に、システムの各パートの性能を詳細に評価します。
-   **利点**: ユーザーへの応答速度に影響を与えることなく、詳細な評価処理を実行できます。

### 2.3. 改善ループ：人間からのフィードバック
-   **役割**: ユーザーからのフィードバックを蓄積し、それを基にナレッジベースやAIモデルを継続的に改善します。これにより、システムが人間と共に進化していきます。

---

## 3. 高度な評価戦略：「スコアカード」方式

システムの性能を単一の総合スコアで評価すると、問題の根本原因が見えにくくなります。そこで、私たちは各パートの重要指標を一覧できる「**スコアカード**」方式を導入します。

### 3.1. スコアカードのイメージ
| 評価カテゴリ | 主要メトリクス | 現在スコア | 状態 (例) |
| :--- | :--- | :--- | :--- |
| **検知モデル性能** | F1スコア (F1-Score) | 0.92 | 🟢 正常 |
| **ナレッジ検索品質** | 再現率 (Context Recall) | 0.85 | 🟡 注意 |
| **分析レポート品質** | 忠実度 (Faithfulness) | 0.98 | 🟢 正常 |
| **総合評価ランク** | (ルールベースで算出) | **A-** | - |

-   **利点**:
    -   **問題点の即時把握**: 「ナレッジ検索の再現率が低下している」といった具体的なボトルネックを瞬時に特定できます。
    -   **具体的なアクションへの誘導**: 評価結果に基づき、「ナレッジDBの拡充」や「モデルの再学習」など、的確な改善アクションに繋げられます。

### 3.2. メトリクスの選定方針：「主役」と「脇役」
評価の焦点がぼやけないよう、各カテゴリで**「最重要メトリクス（主役）」**と**「補助メトリクス（脇役）」**を定めます。

| 評価カテゴリ | **最重要メトリクス (主役)** | **補助メトリクス (脇役)** |
| :--- | :--- | :--- |
| **① 検知モデル性能** | **再現率 (Recall)**<br>_「見逃していないか？」_ | **適合率 (Precision)**<br>_「誤報は多くないか？」_ |
| **② ナレッジ検索品質** | **文脈再現率 (Context Recall)**<br>_「必要な情報を漏れなく探せているか？」_ | **文脈適合率 (Context Precision)**<br>_「無関係な情報が混ざっていないか？」_ |
| **③ 分析レポート品質** | **忠実度 (Faithfulness)**<br>_「AIは嘘をついていないか？」_ | **回答関連性 (Answer Relevancy)**<br>_「問いに的確に答えているか？」_ |

まず**主役の指標**でシステムの致命的な欠陥がないかを確認し、問題の兆候が見られた際に**脇役の指標**で具体的な原因を特定します。

---

## 4. よくある質問（FAQ）

### Q1. なぜ、AIマルチエージェントではなく、AWS Step Functions を使うのですか？
**A1.** マルチエージェントは自律性が高い反面、**動作が予測しにくく、本番システムで求められる信頼性や保守性の確保が困難**な場合があります。一方、AWS Step Functions は以下の点で優れており、今回のシステムに適しています。

-   **確実な処理フロー:** 「検知→分析→レポート作成」といった流れを明確に定義でき、常に期待通りに実行されます。
-   **容易なエラー処理:** 各ステップでの失敗を検知し、自動で再試行させるといった堅牢なエラーハンドリングが簡単に組み込めます。
-   **高い保守性:** 各処理を独立した部品（Lambda関数など）として開発・テストできるため、修正や機能追加が容易です。
-   **デバッグのしやすさ:** 処理の実行状況を視覚的に確認できるため、問題解決が迅速に行えます。

### Q2. なぜ、システム全体をまとめて評価せず、パート別に評価するのですか？
**A2.** **各パートが担う役割（タスク）が全く異なり、それぞれに適した「ものさし（評価指標）」が違う**ためです。

-   **①異常検知**は**『分類タスク』**であり、機械学習の「再現率」や「適合率」で評価するのが適切です。
-   **③ナレッジ活用**は**『RAGタスク』**であり、RAGASの「Faithfulness」や「Context Recall」といった専門指標で評価すべきです。

全体をまとめて評価すると、低いスコアが出た場合に**根本原因の特定が非常に困難**になります。

### Q3. なぜ、実行系と評価系を分離するのですか？
**A3.** **ユーザーへの「応答速度」と、システムの「詳細な性能評価」を両立させるため**です。

-   **実行系**は、まずユーザーへ高速に結果を返すことに集中します。
-   **評価系**は、ユーザーを待たせることなく、バックグラウンドで時間をかけて詳細な評価を行います。

この非同期アーキテクチャにより、ユーザー体験を損なうことなく、システムの健全性を継続的に監視することが可能になります。

### Q4. スコアカード方式の利点は何ですか？
**A4.** 単一の総合スコアでは見えない**システムのボトルネックを可視化できる**点です。例えば、「総合点は良いが、実はナレッジ検索の品質だけが悪化している」といった状況を即座に把握し、他の部分に影響が広がる前に、的確な対策を打つことができます。

### Q5. 人間からのフィードバックは、具体的にどうやってシステム改善に繋げるのですか？
**A7.** フィードバックを以下の3つの改善サイクルに繋げることが重要です。

1.  **ナレッジベースの改善:** 「検索されたナレッジが不適切」というフィードバックが多ければ、ナレッジ自体を見直します。
2.  **プロンプトの改善:** 「回答が意図とズレている」というフィードバックが多ければ、LLMへの指示（プロンプト）を修正します。
3.  **モデルのファインチューニング:** 蓄積された評価データを教師データとして、基盤モデルを定期的にファインチューニングし、人間の好みを学習させます。
