---
marp: true
theme: default
paginate: true
header: 'トークンについて'
footer: '2024年末時点の情報'
---

# 【調査】トークンについて

AIにおけるトークンの基本概念から実用的な活用方法まで

---

## 主な内容

1. **トークンの基本概念** - 文字ではなく意味のある塊として分割される単位
2. **単位の換算** - 1M = 1000k = 100万トークンの関係
3. **文字数との関係** - 英語4文字/日本語2-3文字程度の目安
4. **具体的なイメージ** - 小説5-10冊分の文章量
5. **料金への影響** - 入力・出力トークンの料金計算
6. **実用的なコツ** - トークン節約術と注意点
7. **モデル別特徴** - コンテキスト長と用途別選び方

---

## トークンとは

**トークン**は、AIが文章を処理する際の基本単位です。

文字そのものではなく、**単語や文字の組み合わせを意味のある塊として分割した単位**のことを指します。

### 例：トークンの分割例
- **英語**：「Hello world」→ 「Hello」「world」（2トークン）
- **日本語**：「こんにちは」→ 「こん」「にち」「は」（3トークン）

---

## 単位の換算

### 基本的な単位関係
```
1M tokens = 1,000,000 tokens = 1,000k tokens
- M（メガ）= 100万
- k（キロ）= 1,000
```

### 料金表示での使われ方
- **1M tokens** = **1,000k tokens** = **100万トークン**
- どちらも同じ意味で、表記が異なるだけ

---

## トークンと文字数の関係

### 言語別の目安

| 言語 | 1トークンあたりの文字数 | 100万トークンの文字数 |
|------|----------------------|---------------------|
| **英語** | 約4文字 | 約400万文字 |
| **日本語** | 約2-3文字 | 約200-300万文字 |

---

## 影響要因と注意点

### トークン消費に影響する要因
- **専門用語**：より多くのトークンを消費
- **記号・数字**：トークン消費が増加
- **文章の種類**：技術文書は一般文書より消費が多い

### 効率的な使用のポイント
- 簡潔で分かりやすい表現を心がける
- 不要な装飾語を避ける

---

## 具体的なイメージ

### 日本語での量感
- **小説1冊**：約10-20万文字
- **100万トークン** ≈ **小説5-10冊分**
- **1,000トークン** ≈ **A4用紙2-3枚程度**

### 実用例
```
例：ChatGPTとの会話
- 質問：50トークン
- 回答：200トークン
- 合計：250トークン（1回のやり取り）
```

---

## AIサービスの料金への影響

### 料金計算の仕組み
- **入力トークン**：AIに送信するテキスト
- **出力トークン**：AIが生成するテキスト
- 多くのサービスで**出力料金 > 入力料金**

---

## 料金例（GPT-4.1の場合）

```
入力料金：$2.00/1,000k tokens
出力料金：$8.00/1,000k tokens

10万トークンの場合：
- 入力：$0.20
- 出力：$0.80
```

**出力の方が4倍高い**ことに注意！

---

## 実用的な使い方のコツ

### トークン節約術
1. **簡潔な質問**：不要な情報を削る
2. **分割質問**：長い文章を複数回に分ける
3. **要点整理**：核心部分のみを伝える

### トークン消費の注意点
- **長いプロンプト**：大量のトークンを消費
- **会話履歴**：過去のやり取りも含まれる
- **添付ファイル**：画像・文書も大量消費

---

## モデル別の特徴

### コンテキスト長の違い
- **GPT-4.1**：100万トークン（長文処理可能）
- **Claude 4**：20万トークン（中程度）
- **Gemini 1.5 Pro**：200万トークン（超長文対応）

---

## 用途別の選び方

### 短文処理向け
- 軽量モデル（Haiku、Flash）
- コスト効率重視

### 長文分析向け
- 大容量モデル（Pro、Sonnet）
- 高精度重視

### コスト重視
- 効率モデル（mini、Flash）
- 頻繁な利用に最適

---

## まとめ

- **1M tokens = 100万トークン ≈ 日本語で200-300万文字**
- **実用イメージ：小説5-10冊分の文章量**
- **料金に直結**するため、効率的な使用が重要
- **用途に応じたモデル選択**でコスト最適化が可能

---

## ありがとうございました

**質問・疑問点があればお気軽にどうぞ**

*2024年末時点の情報に基づく。各サービスの料金やトークン計算方法は変更される可能性があります。* 